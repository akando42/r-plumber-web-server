doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
html2txt(case_html)
case_text <- html2txt(case_html)
keywords <- text2topic(case_text)
tibble(case_text)
tibble(case_text) %>% unnest_tokens(word, text)
tibble(case_text) %>% unnest_tokens(word, cool)
View(case_text)
class(case_text)
case_df <- tibble(case_text)
case_text %>% tibble() %>% unnest_tokens(word, cool)
case_text %>% tibble(case_text) %>% unnest_tokens(word, cool)
unnest_tokens(case_df, word, cool)
View(case_df)
case_text %>% tibble() %>% unnest_tokens(word, case_text)
unnest_tokens(case_df, word, case_text)
case_text %>% tibble() %>%  unnest_tokens(word, case_text)
case_text %>% tibble() %>% unnest_tokens(word, case_text)
case_text %>%
tibble() %>%
unnest_tokens(word, case_text)
unnest_tokens(word, text)
coolio <- case_text %>% tibble() %>% unnest_tokens(word, case_text)
case_text
coolio <- case_text %>% tibble() %>% unnest_tokens(word, case_text)
text2topic <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(word,case_df)
words <- anti_join(word_df)
count(words, word, sort=TRUE)
return(words)
}
text2topic(case1)
unnest_tokens(word, case_df)
case_df
unnest_tokens(case_df, word, case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df)
anti_join(word_df)
?anti_join
words <- anti_join(word_df, stop_words)
count(words, word, sort=TRUE)
?count
?count
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
count(words, word, sort=TRUE)
library(stringr)
count(words, word, sort=TRUE)
?count
?count
library(dplyr)
count(words, word, sort=TRUE)
dplyr::count(words, word, sort=TRUE)
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
text2words(case_text)
tidy_case <- text2words(case_text)
tidy_case %>%
count(word, sort = TRUE) %>%
filter(n > 100) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_case %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 100) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_case %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
tidy_case %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into keywords
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
tidy_cases <- text2words(case_text)
word_df <- tidy_cases %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
return (word_df)
}
mine_case_text(caes1)
mine_case_text(case1)
case2 <- mine_case_text(case1)
case2 <- mine_case_text(case1)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
keywords <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
return(keywords)
}
mine_case_text(case1)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
keywords <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
return(c(keywords))
}
mine_case_text(case1)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
keywords <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n))
return(c(keywords))
}
mine_case_text(case1)
keywords <- mine_case_text(case1)
View(keywords)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
keywords <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n))
return(keywords)
}
mine_case_text(case1)
keywords <- mine_case_text(case1)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n))
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
return(plot)
}
mine_case_text(case1)
html2txt <- function(case1){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n))
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
return(plot)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(case_html){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
# library(ggplot2)
# tidy_twilio %>%
#   count(word, sort = TRUE) %>%
#   filter(n > 100) %>%
#   mutate(word = reorder(word, n)) %>%
#   ggplot(aes(word, n)) +
#   geom_col() +
#   xlab(NULL) +
#   coord_flip()
return(plot)
}
mine_case_text(case1)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_contentl){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
# library(ggplot2)
# tidy_twilio %>%
#   count(word, sort = TRUE) %>%
#   filter(n > 100) %>%
#   mutate(word = reorder(word, n)) %>%
#   ggplot(aes(word, n)) +
#   geom_col() +
#   xlab(NULL) +
#   coord_flip()
return(plot)
}
mine_case_text(case1)
mine_case_text <- function(case_html){
## Turn html into Pure Text
html2txt <- function(html_content){
# Read and parse HTML file
doc.html = htmlTreeParse(html_content, useInternal=TRUE)
# Extract all the paragraphs (HTML tag is p, starting at
# the root of the document). Unlist flattens the list to
# create a character vector.
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
# Replace all by spaces
doc.text = gsub('\n', ' ', doc.text)
# Join all the elements of the character vector into a single
# character string, separated by spaces
#doc.text = paste(doc.text, collapse = ' ')
return(doc.text)
}
case_text <- html2txt(case_html)
## Turn text into words
text2words <- function(case_text){
case_df <- tibble(case_text)
word_df <- unnest_tokens(case_df, word, case_text)
words <- anti_join(word_df, stop_words)
dplyr::count(words, word, sort=TRUE)
return(words)
}
word_df <- text2words(case_text)
## find keywords
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
# library(ggplot2)
# tidy_twilio %>%
#   count(word, sort = TRUE) %>%
#   filter(n > 100) %>%
#   mutate(word = reorder(word, n)) %>%
#   ggplot(aes(word, n)) +
#   geom_col() +
#   xlab(NULL) +
#   coord_flip()
return(plot)
}
mine_case_text(case1)
plot <- word_df %>%
dplyr::count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
